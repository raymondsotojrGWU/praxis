{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "631750a7-d271-4cd8-9663-85c3506e9639",
   "metadata": {},
   "source": [
    "#### Copyright Raymond Soto Jr. D.Eng(c).\n",
    "#### From Edge to Enterprise: \n",
    "#### Federated Learning Threat Classification with Heterogeneous Devices in Converged Energy Sector Networks\n",
    "#### Revised for Github on July 9th, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbb6f8f-50ff-4911-a813-9c607f4fc0ce",
   "metadata": {},
   "source": [
    "# Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "id": "7df258f5-63c4-4052-a950-1f42b3cd9fdc",
   "metadata": {},
   "source": [
    "# Load Program Modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "from xgboost import XGBClassifier \n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import StratifiedKFold, ParameterGrid\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# TensorFlow Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "168790c7-9f5b-4b63-af26-8190f5d925fe",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "2966dfc8-d2d6-4745-9fdd-792df70d23db",
   "metadata": {},
   "source": [
    "# imports the feature descriptions csv to work with the full traffic dataset\n",
    "unswnb15_features = pd.read_csv('UNSWB15_CSV_Files/UNSW-NB15_features.csv')\n",
    "# convert the feature names into a list\n",
    "feature_header = unswnb15_features['Name'].tolist()\n",
    "# import UNSW NB traffic dataset part 1 without headers, then map the list of headers, and silence low memory alert\n",
    "df1 = pd.read_csv('UNSWB15_CSV_Files/UNSW-NB15_1.csv',header=None, names=feature_header , low_memory=False)\n",
    "df2 = pd.read_csv('UNSWB15_CSV_Files/UNSW-NB15_2.csv',header=None, names=feature_header , low_memory=False)\n",
    "df3 = pd.read_csv('UNSWB15_CSV_Files/UNSW-NB15_3.csv',header=None, names=feature_header , low_memory=False)\n",
    "df4 = pd.read_csv('UNSWB15_CSV_Files/UNSW-NB15_4.csv',header=None, names=feature_header , low_memory=False)\n",
    "# print shape of each dataframe\n",
    "print(df1.shape)\n",
    "print(df2.shape)\n",
    "print(df3.shape)\n",
    "print(df4.shape)\n",
    "# Assume 'label' column indicates 1 for malicious, 0 for normal\n",
    "# Ensure class distribution is examined, Print out the percentage of malicious vs normal instances\n",
    "label_col = 'label'\n",
    "print(df1[label_col].value_counts(normalize=True) * 100)\n",
    "print(df2[label_col].value_counts(normalize=True) * 100)\n",
    "print(df3[label_col].value_counts(normalize=True) * 100)\n",
    "print(df4[label_col].value_counts(normalize=True) * 100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0276d234-5957-4fdd-8fd7-2f3e2d03a657",
   "metadata": {},
   "source": [
    "#### Combine CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "id": "6e112117-52e8-4bb9-847b-cbddb2a1e43f",
   "metadata": {},
   "source": [
    "# combined dataframe df1, df2, df3, d4\n",
    "df_combined = pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
    "print(\"Combined DataFrame shape:\", df_combined.shape)\n",
    "print(df_combined[label_col].value_counts(normalize=True) * 100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "83009dd7-c4da-44b8-88b8-e63b890e413e",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc2fd34-d81b-43cd-9afa-c78d7d39a11e",
   "metadata": {},
   "source": [
    "#### Map Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8a63e04-94d7-496a-843e-22deadca68b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create map_protocol function to group network traffic protocols\n",
    "def map_protocol(proto):\n",
    "    if proto in [\"tcp\", \"udp\", \"sctp\", \"udt\", \"mux\", \"iso-tp4\", \"tp++\", \"ddp\", \"xtp\", \"vmtp\", \"mtp\", \"crudp\"]:\n",
    "        return \"transport\"\n",
    "    elif proto in [\"icmp\", \"igmp\", \"rsvp\", \"ptp\"]:\n",
    "        return 'control'\n",
    "    elif proto in [\"ospf\", \"egp\", \"igp\", \"idrp\", \"ipv6-route\", \"gre\", \"nsfnet-igp\", \"eigrp\", \"isis\", \"vrrp\"]:\n",
    "        return \"Routing\"\n",
    "    elif proto in [\"ip\", \"ipv6\", \"ipv6-frag\", \"ipv6-opts\", \"iso-ip\", \"ipnip\", \"ggp\", \"ipip\", \"ipx-n-ip\"]:\n",
    "        return \"Internet\"\n",
    "    elif proto in [\"pim\", \"rtp\", \"gmtp\", \"micp\", \"pgm\"]:\n",
    "        return \"Multicast\"\n",
    "    elif proto in [\"etherip\", \"l2tp\", \"encap\"]:\n",
    "        return \"Tunneling\"\n",
    "    elif proto in [\"arp\", \"stp\", \"ax.25\", \"fc\", \"ib\"]:\n",
    "        return \"Link\"\n",
    "    elif proto in [\"esp\", \"ipcomp\", \"secure-vmtp\"]:\n",
    "        return \"Security\"\n",
    "    else:\n",
    "        return \"other\"\n",
    "\n",
    "# Use map_protocol function to build a new column with categories from the Train set\n",
    "df_combined['protocol_category'] = df_combined['proto'].apply(map_protocol)\n",
    "# drop original proto column before OneHot encoding 'protocol_category'\n",
    "df_combined.drop(['proto'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a379bb-2dae-4f5e-9f4f-e0bd83e4ac86",
   "metadata": {},
   "source": [
    "#### Map Connection State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b44aa1e-21d1-4f12-be9c-b6ab557b1a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates map_connection_state function that maps connection state values to broader groups.\n",
    "def map_connection_state(state):\n",
    "    # Group states that indicate an established connection\n",
    "    if state in [\"CON\", \"ACC\", \"REQ\"]:\n",
    "        return \"established\"\n",
    "    # Group states that indicate termination of the connection\n",
    "    elif state in [\"FIN\", \"RST\", \"CLO\"]:\n",
    "        return \"terminated\"\n",
    "    # Group states that might indicate the handshake phase (if applicable)\n",
    "    elif state in [\"SYN\", \"SYN-ACK\"]:\n",
    "        return \"handshaking\"\n",
    "    else:\n",
    "        return \"other\"\n",
    "\n",
    "# use map_connection_state function to build a new column with categories from the combined set\n",
    "df_combined['state_category'] = df_combined['state'].apply(map_connection_state)\n",
    "# drop original proto column before OneHot encoding 'protocol_category'\n",
    "df_combined.drop(['state'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61254fe2-1a0c-4641-83db-c4e2f5ca7914",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19229a87-58be-4ff0-87d2-3ae0c254a42c",
   "metadata": {},
   "source": [
    "#### Feature Reduction: Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "id": "f8fde906-0396-4ad3-914e-38c14fcdf91e",
   "metadata": {},
   "source": [
    "# drop columns to align the shape of the dataframes\n",
    "df_combined.drop(['srcip','sport','dstip','service','stime','ltime','is_sm_ips_ports',\n",
    "                  'ct_ftp_cmd','ct_flw_http_mthd','is_ftp_login','attack_cat'],axis=1, inplace=True)\n",
    "\n",
    "# print dataframe shape\n",
    "print(f'DF Shape Combined Set {df_combined.shape}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "703a0fb7-d28c-4339-b6f7-3d9818f3f8d9",
   "metadata": {},
   "source": [
    "#### Drops Rows of Invalid Hex and Regex and Convert to int"
   ]
  },
  {
   "cell_type": "code",
   "id": "45a92b46-346c-4595-9156-a8682b34ae92",
   "metadata": {},
   "source": [
    "# Build a boolean mask for rows where dsport looks like a hex string or regex\n",
    "mask_hex = df_combined['dsport'].astype(str).str.lower().str.startswith('0x')\n",
    "mask_digits = df_combined['dsport'].astype(str).str.fullmatch(r'\\d+')\n",
    "\n",
    "# Drop rows\n",
    "df_combined = df_combined.loc[~mask_hex].copy()\n",
    "df_combined = df_combined.loc[mask_digits].copy()\n",
    "\n",
    "# Convert the remaining dsport values to int\n",
    "df_combined['dsport'] = df_combined['dsport'].astype(int)\n",
    "\n",
    "# Quick sanity check\n",
    "print(\"Remaining dsport dtype:\", df_combined['dsport'].dtype)\n",
    "print(\"Any hex rows left?\", df_combined['dsport'].astype(str).str.lower().str.startswith('0x').any())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "701f81cc-0b41-4f60-bd8d-f66fdfacb083",
   "metadata": {},
   "source": [
    "#### Convert to Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94242d3b-fa51-458b-9066-6d478c76799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conver label to a boolean type\n",
    "df_combined['label'] = df_combined['label'].astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99add902-cba5-4f36-b651-c0100f616bad",
   "metadata": {},
   "source": [
    "#### Categorical Encoding: One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "id": "fb10984b-fd96-4009-923e-05932d7be221",
   "metadata": {},
   "source": [
    "# OneHotEncoding\n",
    "# Select the columns to be one-hot encoded\n",
    "cols_to_encode = ['protocol_category','state_category']\n",
    "# Create the OneHotEncoder instance with the desired parameters\n",
    "encoder = OneHotEncoder(dtype=bool, sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit and transform the selected columns from the Combined set. This returns a NumPy array.\n",
    "encoded_array_combined = encoder.fit_transform(df_combined[cols_to_encode])\n",
    "# Retrieve the names for the new columns\n",
    "encoded_columns_combined = encoder.get_feature_names_out(cols_to_encode)\n",
    "# Convert the encoded array to a DataFrame. Preserve the index to merge correctly.\n",
    "encoded_df_combined = pd.DataFrame(encoded_array_combined, columns=encoded_columns_combined, index=df_combined.index)\n",
    "# Drop the original columns and concatenate the one-hot encoded DataFrame\n",
    "df_encoded_combined = pd.concat([df_combined.drop(columns=cols_to_encode), encoded_df_combined], axis=1)\n",
    "\n",
    "# Print to confirm\n",
    "print(f'DF Combined Shape Combined Set {df_encoded_combined.shape}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8a10e8f0-64af-42fe-bf97-455a559e7f87",
   "metadata": {},
   "source": [
    "#### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "c7459f44-efe8-4916-8456-9e089e7f321b",
   "metadata": {},
   "source": [
    "# Confirm proportions of malicious/benign and dataframe size\n",
    "label_col = 'label'\n",
    "print(df_encoded_combined[label_col].value_counts(normalize=True) * 100)\n",
    "print(f'DF Encoded Combined Shape: {df_encoded_combined.shape}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2f88ea3d-0436-4149-bd55-30d61053ec53",
   "metadata": {},
   "source": [
    "# Split dataset to seperate the testing set before training and validation\n",
    "strat_col = 'label'\n",
    "\n",
    "df_encoded_combined, df_encoded_4 = train_test_split(\n",
    "    df_encoded_combined,\n",
    "    test_size=0.20,\n",
    "    stratify=df_encoded_combined[strat_col]\n",
    ")\n",
    "\n",
    "# Confirm\n",
    "print(f\"Train & Validate shape: {df_encoded_combined.shape},  Test shape: {df_encoded_4.shape}\")\n",
    "print(\"Train True proportion:\", df_encoded_combined[strat_col].mean())\n",
    "print(\"Test  True proportion:\", df_encoded_4[strat_col].mean())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f06a110d-1b5f-43c2-aaf1-2c92a7dbdd71",
   "metadata": {},
   "source": [
    "# Train, Validation, Testing Split"
   ]
  },
  {
   "cell_type": "code",
   "id": "99e532ed-6edd-4b2d-a30b-65bc299924e1",
   "metadata": {},
   "source": [
    "# split the combined dataset into testing and validation\n",
    "X_train0 = df_encoded_combined.drop(['label'], axis=1) # set X as all features/predicator variables\n",
    "y_train0 = df_encoded_combined['label'].astype(bool) # set y as target variable\n",
    "\n",
    "# confirm distribution of malicous to normal: REMOVED for testing , random_state=42\n",
    "print(X_train0.shape)\n",
    "print(y_train0.value_counts(normalize=True) * 100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f0df4a95-7147-45c3-af53-447467aad82d",
   "metadata": {},
   "source": [
    "# split the testing dataset\n",
    "X2 = df_encoded_4.drop(['label'], axis=1) # set X as all features/predicator variables\n",
    "y2 = df_encoded_4['label'].astype(bool) # set y as target variable\n",
    "# confirm distribution of malicous to normal\n",
    "print(y2.value_counts(normalize=True) * 100)\n",
    "print(X2.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8ecf20c1-e7d0-4eca-a499-79efdb0677b2",
   "metadata": {},
   "source": [
    "#### Feature Standardization: Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76abd6ab-588b-49fb-a385-5e61e975fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric columns in your training set\n",
    "numeric_cols = X_train0.select_dtypes(include=[np.number]).columns\n",
    "# Create and fit the scaler on TRAINING data\n",
    "scaler = StandardScaler()\n",
    "X_train0[numeric_cols] = scaler.fit_transform(X_train0[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c58199f-c89d-48f7-8758-cbc241781212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform your testing data \n",
    "X2[numeric_cols] = scaler.transform(X2[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "id": "e3f1cf59-7694-4e7a-b977-357c95e79fca",
   "metadata": {},
   "source": [
    "# Confirm StandardScaler\n",
    "# Compute separately\n",
    "means0 = X_train0[numeric_cols].mean()\n",
    "stds0  = X_train0[numeric_cols].std()\n",
    "# Show the top 5 means and stds\n",
    "print(\"Means:\\n\", means0.head(), \"\\n\")\n",
    "print(\"Stds:\\n\",  stds0.head(), \"\\n\")\n",
    "\n",
    "means2 = X2[numeric_cols].mean()\n",
    "stds2  = X2[numeric_cols].std()\n",
    "# Show the top 5 means and stds\n",
    "print(\"Means:\\n\", means2.head(), \"\\n\")\n",
    "print(\"Stds:\\n\",  stds2.head(), \"\\n\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4c2c600d-eb07-4bd1-aa34-66ea10c4ace0",
   "metadata": {},
   "source": [
    "# Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d030db-7d31-4fde-a86b-3489fda70bbe",
   "metadata": {},
   "source": [
    "#### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "id": "db08fe2f-5e08-4174-b3c3-a860a2d4e52a",
   "metadata": {},
   "source": [
    "# SMOTE will increase the count of miniroty items\n",
    "# Apply SMOTE to training data only\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train0, y_train0)\n",
    "print(\"Before SMOTE:\", y_train0.value_counts())\n",
    "print(\"After SMOTE:\", y_train_smote.value_counts())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a8f67304-d7ce-44df-90a9-a167f5577387",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5756d1-5d0c-4d4c-a35a-bd39d0a0f657",
   "metadata": {},
   "source": [
    "#### Convert to Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb21681f-7717-4ef6-9a68-0f74d4c07e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow operations and the tf.data.Dataset API expect data \n",
    "# in a format that it can work with efficiently—typically NumPy arrays or tensors.\n",
    "X_train_smote_np = X_train_smote.to_numpy(dtype=np.float32)\n",
    "y_train_smote_np = y_train_smote.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13e73d7-f486-45e3-bc10-b909c588f8ad",
   "metadata": {},
   "source": [
    "## Automated grid search with K-fold cross-validation for a Keras MLP model"
   ]
  },
  {
   "cell_type": "code",
   "id": "b8fca634-7794-4b55-8a6a-ec358d835e4d",
   "metadata": {},
   "source": [
    "# --- 0. Your SMOTE-resampled data and split helper ---\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# --- 1. Define your hyperparameter grid ---\n",
    "param_grid = {\n",
    "    'learning_rate': [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    'activation':    ['relu', 'elu'],\n",
    "    'hidden_layer_sizes': [(128, 64), (64, 32)]\n",
    "}\n",
    "\n",
    "# --- 2. EarlyStopping callback factory ---\n",
    "def make_early_stop():\n",
    "    return EarlyStopping(\n",
    "        monitor='val_recall',\n",
    "        patience=20,\n",
    "        verbose=1,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "# --- 3. Outer grid loop ---\n",
    "start_time = time.time()\n",
    "for params in ParameterGrid(param_grid):\n",
    "    lr  = params['learning_rate']\n",
    "    act = params['activation']\n",
    "    hl1, hl2 = params['hidden_layer_sizes']\n",
    "    print(f\"\\n=== GRID SEARCH: lr={lr}, activation={act}, hidden=[{hl1},{hl2}] ===\")\n",
    "\n",
    "    # --- 3a. Model factory that “captures” these params ---\n",
    "    def create_mlp_model():\n",
    "        m = models.Sequential([\n",
    "            layers.Input(shape=(47,)),\n",
    "            layers.Dense(hl1, activation=act),\n",
    "            layers.Dense(hl2, activation=act),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        opt = optimizers.Adam(learning_rate=lr)\n",
    "        m.compile(\n",
    "            optimizer=opt,\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=[\n",
    "                'binary_accuracy',\n",
    "                tf.keras.metrics.Precision(name='precision'),\n",
    "                tf.keras.metrics.Recall(name='recall')\n",
    "            ]\n",
    "        )\n",
    "        return m\n",
    "\n",
    "    # --- 3b. 5-fold CV for this combination ---\n",
    "    best_model = None\n",
    "    best_val_recall = 0.0\n",
    "    fold_no = 1\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_train_smote_np, y_train_smote_np):\n",
    "        print(f\"-- Fold {fold_no} --\")\n",
    "        X_tr, X_va = X_train_smote_np[train_idx], X_train_smote_np[val_idx]\n",
    "        y_tr, y_va = y_train_smote_np[train_idx], y_train_smote_np[val_idx]\n",
    "\n",
    "        train_ds = (\n",
    "            tf.data.Dataset\n",
    "              .from_tensor_slices((X_tr, y_tr))\n",
    "              .shuffle(len(X_tr))\n",
    "              .batch(64)\n",
    "              .prefetch(tf.data.AUTOTUNE)\n",
    "        )\n",
    "        val_ds = (\n",
    "            tf.data.Dataset\n",
    "              .from_tensor_slices((X_va, y_va))\n",
    "              .batch(64)\n",
    "              .prefetch(tf.data.AUTOTUNE)\n",
    "        )\n",
    "\n",
    "        model = create_mlp_model()\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            epochs=100,\n",
    "            validation_data=val_ds,\n",
    "            callbacks=[make_early_stop()],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # best recall this fold\n",
    "        fold_recall = max(history.history['val_recall'])\n",
    "        print(f\"Fold {fold_no} best val_recall: {fold_recall:.4f}\")\n",
    "\n",
    "        if fold_recall > best_val_recall:\n",
    "            best_val_recall = fold_recall\n",
    "            best_model = model\n",
    "\n",
    "        fold_no += 1\n",
    "\n",
    "    # --- 3c. Save the best model for *this* param combo ---\n",
    "    if best_model is not None:\n",
    "        fname = f\"mlp_lr{lr}_act{act}_hl{hl1}-{hl2}.h5\"\n",
    "        best_model.save(fname)\n",
    "        print(f\"Saved best model (recall={best_val_recall:.4f}) → {fname}\")\n",
    "\n",
    "# --- 4. Summary timing ---\n",
    "elapsed = time.time() - start_time\n",
    "print(\"Grid search complete — total time: {:.2f}s\".format(elapsed))\n",
    "print(\"Finished at\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8186d658-9096-4308-9503-dd1762009053",
   "metadata": {},
   "source": [
    "## Change model names"
   ]
  },
  {
   "cell_type": "code",
   "id": "7f57b5c6-01d1-4cf4-b769-30a0929e71d8",
   "metadata": {},
   "source": [
    "# Define the filenames for the source and destination lists\n",
    "source_list_filename = \"s_names.txt\"\n",
    "destination_list_filename = \"d_names.txt\"\n",
    "\n",
    "try:\n",
    "    # --- 1. Read the lists of filenames ---\n",
    "    with open(source_list_filename, 'r') as f:\n",
    "        # Use strip() to remove newline characters from each line\n",
    "        source_files = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    with open(destination_list_filename, 'r') as f:\n",
    "        destination_files = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    # --- 2. Validate that the lists are the same size ---\n",
    "    if len(source_files) != len(destination_files):\n",
    "        print(\"Error: The source and destination lists have a different number of entries.\")\n",
    "        exit() # Stop the script if lists don't match\n",
    "\n",
    "    # --- 3. Loop through the files and copy them ---\n",
    "    print(f\"Found {len(source_files)} file(s) to copy.\\n\")\n",
    "    for source, dest in zip(source_files, destination_files):\n",
    "        try:\n",
    "            # Check if the source file exists\n",
    "            if os.path.exists(source):\n",
    "                # Copy the file (shutil.copy also works)\n",
    "                shutil.copy(source, dest)\n",
    "                print(f\"✅ Successfully copied '{source}' to '{dest}'\")\n",
    "            else:\n",
    "                print(f\"❌ Error: Source file '{source}' not found.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            # This catches errors during the copy process itself\n",
    "            print(f\"❌ An error occurred while processing '{source}': {e}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    # This catches an error if s_names.txt or d_names.txt is missing\n",
    "    print(f\"❌ Error: A list file was not found. Please ensure '{source_list_filename}' and '{destination_list_filename}' exist.\")\n",
    "    print(f\"   Details: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    # This catches any other unexpected errors\n",
    "    print(f\"❌ An unexpected error occurred: {e}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "646be148-638a-49f6-a1ab-506a3a156cd5",
   "metadata": {},
   "source": "# Model Testing"
  },
  {
   "cell_type": "code",
   "id": "ea3a7b2a-7470-4c33-a983-7fe6b10f37dc",
   "metadata": {},
   "source": [
    "# --- Configuration ---\n",
    "MODEL_PATH_TEMPLATE = 'M{}.h5' # Template for model filenames\n",
    "NUM_MODELS = 16\n",
    "\n",
    "X2_np = X2.to_numpy(dtype=np.float32)\n",
    "y2_np = y2.to_numpy(dtype=np.int32)\n",
    "\n",
    "# --- Initialize lists to store metrics ---\n",
    "model_names = []\n",
    "recalls = []\n",
    "accuracies = []\n",
    "fprs = [] # False Positive Rates\n",
    "fnrs = [] # False Negative Rates\n",
    "\n",
    "# --- Loop through each model ---\n",
    "for i in range(1, NUM_MODELS + 1):\n",
    "    model_name = f\"M{str(i).zfill(2)}\" # Ensures names like LR01, LR02, ..., LR16\n",
    "    model_file = MODEL_PATH_TEMPLATE.format(str(i).zfill(2))\n",
    "    print(f\"\\n--- Processing Model: {model_name} ({model_file}) ---\")\n",
    "\n",
    "    try:\n",
    "        # Load the saved model\n",
    "        model = tf.keras.models.load_model(model_file)\n",
    "        print(f\"Model {model_name} loaded successfully.\")\n",
    "\n",
    "        # Use the model to predict probabilities, then convert to binary predictions\n",
    "        y_pred_prob = model.predict(X2_np)\n",
    "        y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "        # Compute the confusion matrix\n",
    "        cm = confusion_matrix(y2_np, y_pred)\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm)\n",
    "\n",
    "        # Extract TP, FP, TN, FN\n",
    "        # Ensure cm has 2x2 shape, otherwise handle appropriately\n",
    "        if cm.shape == (2, 2):\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "        elif cm.shape == (1, 1): # Handle case where only one class is predicted or present\n",
    "            if y2_np[0] == 0 and y_pred[0] == 0: # All TN\n",
    "                tn, fp, fn, tp = cm[0][0], 0, 0, 0\n",
    "            elif y2_np[0] == 1 and y_pred[0] == 1: # All TP\n",
    "                tn, fp, fn, tp = 0, 0, 0, cm[0][0]\n",
    "            elif y2_np[0] == 0 and y_pred[0] == 1: # All FP (tn=0, fn=0, tp=0)\n",
    "                 tn, fp, fn, tp = 0, cm[0][0], 0, 0\n",
    "            elif y2_np[0] == 1 and y_pred[0] == 0: # All FN (tn=0, fp=0, tp=0)\n",
    "                 tn, fp, fn, tp = 0, 0, cm[0][0], 0\n",
    "            else: # Should not happen with binary classification if data exists\n",
    "                print(f\"Warning: Confusion matrix for {model_name} has unexpected shape: {cm.shape}. Setting metrics to NaN.\")\n",
    "                tn, fp, fn, tp = 0,0,0,0 # Or handle as an error\n",
    "\n",
    "        else:\n",
    "            print(f\"Warning: Confusion matrix for {model_name} is not 2x2 or 1x1 ({cm.shape}). Skipping metric calculation.\")\n",
    "            recalls.append(float('nan'))\n",
    "            accuracies.append(float('nan'))\n",
    "            fprs.append(float('nan'))\n",
    "            fnrs.append(float('nan'))\n",
    "            model_names.append(model_name)\n",
    "            continue\n",
    "\n",
    "\n",
    "        # Calculate metrics (handle potential division by zero if a class is not present or not predicted)\n",
    "        # Recall (Sensitivity or True Positive Rate): TP / (TP + FN)\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        # Accuracy: (TP + TN) / (TP + TN + FP + FN)\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0.0\n",
    "        # False Positive Rate (FPR): FP / (FP + TN)\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "        # False Negative Rate (FNR): FN / (TP + FN)\n",
    "        fnr = fn / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"False Positive Rate: {fpr:.4f}\")\n",
    "        print(f\"False Negative Rate: {fnr:.4f}\")\n",
    "\n",
    "        # Append metrics and model name\n",
    "        model_names.append(model_name)\n",
    "        recalls.append(recall)\n",
    "        accuracies.append(accuracy)\n",
    "        fprs.append(fpr)\n",
    "        fnrs.append(fnr)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Model file {model_file} not found. Skipping.\")\n",
    "        # Append NaN or placeholder if you want to keep the graph structure consistent\n",
    "        model_names.append(model_name + \" (Not Found)\")\n",
    "        recalls.append(float('nan'))\n",
    "        accuracies.append(float('nan'))\n",
    "        fprs.append(float('nan'))\n",
    "        fnrs.append(float('nan'))\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {model_name}: {e}\")\n",
    "        model_names.append(model_name + \" (Error)\")\n",
    "        recalls.append(float('nan'))\n",
    "        accuracies.append(float('nan'))\n",
    "        fprs.append(float('nan'))\n",
    "        fnrs.append(float('nan'))\n",
    "\n",
    "\n",
    "# --- Create a DataFrame for plotting ---\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Recall': recalls,\n",
    "    'Accuracy': accuracies,\n",
    "    'FPR': fprs,\n",
    "    'FNR': fnrs\n",
    "})\n",
    "\n",
    "# --- Generate the labeled bar graph ---\n",
    "if not metrics_df.empty:\n",
    "\n",
    "    # Melt the DataFrame for easier plotting with Seaborn or Matplotlib\n",
    "    metrics_melted = metrics_df.melt(id_vars='Model', var_name='Metric', value_name='Score')\n",
    "\n",
    "    plt.figure(figsize=(18, 10)) # Adjust figure size as needed\n",
    "    sns.barplot(x='Model', y='Score', hue='Metric', data=metrics_melted, palette='viridis')\n",
    "\n",
    "    plt.title('Model Performance Metrics (LR01-LR16)', fontsize=16)\n",
    "    plt.xlabel('Model', fontsize=14)\n",
    "    plt.ylabel('Score', fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=10) # Rotate x-axis labels for better readability\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.legend(title='Metric', fontsize=10, title_fontsize=12)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout() # Adjust layout to prevent labels from overlapping\n",
    "    plt.show()\n",
    "    print(\"\\nBar graph generated.\")\n",
    "\n",
    "    # --- Optional: Print the metrics DataFrame ---\n",
    "    print(\"\\n--- Summary of Metrics ---\")\n",
    "    print(metrics_df.to_string())\n",
    "\n",
    "else:\n",
    "    print(\"\\nNo metrics were calculated, skipping plot generation.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a349f3-8450-40f8-ad20-9346f11f29b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
